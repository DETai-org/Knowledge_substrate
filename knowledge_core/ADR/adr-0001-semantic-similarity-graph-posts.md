# ADR-0001: Semantic Similarity Graph for Posts (Publish Only)

## Status
Accepted

## Date
2026-02-03

## Context
В экосистеме DET / DETai уже существует канонический Source of Truth (SoT) для публикаций типа `post`
в формате Markdown + frontmatter, а также контролируемые словари (rubrics/categories/keywords).
На сайте (Next.js) уже работает фильтрация и листинг постов по метаданным (frontmatter), т.е. поиск/фильтры
по рубрикам/категориям/годам/авторам решены на уровне статических данных.

Текущая практическая цель: получить семантическую карту (граф) смысловой близости опубликованных постов, чтобы:
- увидеть кластеры смыслов и "центральные" узлы,
- сформулировать постулаты и опорные концепции DET для сайта,
- подготовить убедимую концептуальную витрину перед набором команды (1–1.5 месяца).

При этом не все типы документов (quote/research_publication/concept/ecosystem) готовы по контрактам/реализации,
поэтому решение должно:
- не требовать готовности всех типов документов,
- быть расширяемым на будущие типы без переписывания системы,
- минимизировать сложность до уровня, достаточного для графа смыслов по постам.

## Decision
1) Scope: строим семантический граф только для документов типа `post` со статусом `publish` (G1).
2) Source: тексты берём напрямую из SoT (S1), используя Markdown + frontmatter как канон.
3) Storage: результаты сохраняем в Operational Store (Postgres) и отдаём через API (H2).
4) Embeddings strategy:
   - используем **document embeddings**: 1 embedding на 1 пост,
   - **chunk embeddings не делаем** на этом этапе.
5) Graph construction strategy:
   - используем **Top-K** подход: для каждого поста сохраняем K наиболее близких постов,
   - применяем дополнительный минимальный порог similarity (min_similarity) как предохранитель от шумовых связей.
6) API contract: добавляем endpoint (например `/graph`) для выдачи `nodes + edges` графа,
   фильтруя только publish-посты.

## Rationale (Why)
- Семантический граф требует устойчивого слоя хранения и быстрых запросов; Postgres + API дают стабильную архитектуру.
- Top-K гарантирует, что у каждого узла есть связи, и граф не станет пустым при высоком пороге.
- Document-level embeddings достаточно для задачи "пост ↔ пост" (кластеризация и карта смыслов).
- Chunk embeddings и RAG добавляют сложность (чанкинг, повторная векторизация, поиск по кускам) и не нужны
  для первичной смысловой карты; это переносится в следующий этап (agent/RAG layer).

## Consequences
### Positive
- Быстро получаем граф смыслов на сайте (Next.js) через API, не ломая текущую систему публикаций.
- Архитектура не зависит от наличия контрактов для других типов документов: расширение возможно по мере готовности.
- Граф можно обновлять идемпотентно при изменении SoT.

### Negative / Trade-offs
- На старте граф строится только по постам, остальные типы документов не включены.
- Потребуются дополнительные компоненты: векторизация и хранение similarity edges (это +1 слой сложности).
- Threshold-only подход не используется, поэтому возможны связи "вынужденные" (Top-K) — компенсируется min_similarity.

## Alternatives Considered
- A1: Threshold-only граф (only edges where similarity >= T).
  - Отказ: риск получить пустой или чрезмерно разреженный граф; сложно подобрать T.
- A2: Chunk embeddings сразу.
  - Отказ: избыточно для задачи "пост ↔ пост"; усложняет pipeline и качество зависит от чанкинга.
- A3: Хранить граф как JSON-файл (H1).
  - Отказ: менее удобно для API, версионирования/обновлений, фильтров и будущего расширения (особенно при росте объёма).

## Follow-up (Next)
- Определить точные параметры: embedding model, K, min_similarity.
- Реализовать pipeline: parse SoT -> embed -> build edges -> upsert in DB.
- Добавить API `/graph` и страницу визуализации в Next.js (Cytoscape/Sigma/D3).
