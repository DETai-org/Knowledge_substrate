# Ingest & RAG — Hybrid Model (Frontmatter + Index)
**v1.0** ♻️

## Зачем этот документ

Фиксируем каноническую модель хранения и доступа к публикациям в DET / DETai:

- **в Markdown-файле** хранится минимальная мета + контент (Source of Truth)
- **в БД/индексе** хранится всё производное и тяжёлое
- агенты и поиск работают **через индекс**, а не через чтение сырых файлов

Цель: избежать рассинхрона, обеспечить масштабируемость и снизить токенный “шум”.

---

## 1) Каноническая модель C: Гибрид

### Внутри файла (минимальная мета + контент)
Markdown-файл содержит:
- frontmatter (минимальная мета)
- тело контента (чистый текст)

Минимальная мета (пример):
```
type: post
id: eta-istoriya-pro-odnogo-cheloveka
slug: eta-istoriya-pro-odnogo-cheloveka
authors:
  - Anton
date_ymd: 2016-05-16
status: publish
title: "Эта история про одного человека"
preview: "История о том, как желание добиться успеха проверяется на прочность."
seoLead: "Притча о том, что настоящий успех приходит, когда ты хочешь его так же, как хочешь жить."
taxonomy:
  rubric_ids: ["rubric:orientation-toward-overcoming"]
  category_ids: ["category:overcoming"]
  keyword_ids: ["keyword:existential-choice"]
  keywords_raw: ["успех", "преодоление", "мотивация"]
```

⚠️ Для type: research_publication и цитат другая МЕТА будет немного 

### В БД / индексе (тяжёлое и производное)
Хранится и обновляется ingestion pipeline:
- embeddings (document + chunk)
- chunk map / разбиение на чанки
- fulltext index
- вычисленные подсказки (например, keyword candidates)
- граф-связи (derived links)
- любые computed/derived поля

---

## 2) Главный принцип: Агент не читает сырые Markdown для поиска

Страх: агент нашёл документ в “таблице”, открыл файл и снова “съел” мету.

Правильный режим:
1) агент делает запрос к API/БД (фильтры/семантика/граф)
2) получает `id` + нужные поля (title/abstract/preview/snippet и т.п.)
3) только при необходимости запрашивает:
   - content документа
   - или конкретные чанки

Итого агент читает:
- metadata из БД (уже распарсенную)
- content по необходимости
- chunks, а не весь файл

В этой модели frontmatter внутри markdown не мешает:
- ingest съедает его один раз
- дальше агент работает с индексом

---

## 3) Два правила реализации, чтобы мета не мешала RAG

### Правило 1: Мета должна легко отделяться
Frontmatter всегда в начале файла и строго ограничен:
- YAML между `--- ... ---`
- или JSON-блок первым куском

Ingest обязан:
- вытащить мету
- удалить мету из чистого текста
- в embeddings отправлять только content

### Правило 2: Embeddings строятся не по всему файлу
Векторизация строится по:
- `content` без frontmatter
- чанкам тела текста
- (опционально) отдельно по title/abstract

Это соответствует модели:
- 1 vector per doc
- N vectors per chunks

---

## 4) Что НЕ класть в метаблок (чтобы не раздувать frontmatter)

Не хранить внутри Markdown:
- IDs embeddings
- chunk map
- extracted entities
- computed keyword suggestions
- derived graph links
- search index fields

Это всё относится к ingestion/индексу и должно жить в БД.

---

## 5) Построение семантического графа постов (derived links)

### Стратегия
- Top-K per document.

### Параметры и управление
Настройки графа управляются через [config.json](../config.json) в секции `graph.*`:
- `graph.top_k` (K)
- `graph.min_similarity`

### Начальные значения
- `K = 8`
- `min_similarity = 0.75`

### Ограничения
- для каждого поста сохраняется не более `K` связей;
- связи с `similarity < min_similarity` отбрасываются;
- граф undirected:
  - рёбра нормализуются как `(min(idA, idB), max(idA, idB))`.

### Поведение
- embeddings пересчитываются только для документов с изменившимся `source_hash`;
- similarity edges пересобираются для затронутых документов;
- допускается полный пересчёт графа как fallback (например, параметром запуска).

На старте допустима реализация полного пересчёта, если это упрощает код,
но интерфейс должен позволять инкрементальную стратегию в будущем.

---

**Статус документа:** canonical  

**Последнее обновление:** 2026-01-15
