# INGEST PIPELINE / ПАЙПЛАЙН ЗАГРУЗКИ

## Что это такое (по-человечески)
Ingest pipeline — это конвейер, который **берёт канонические документы из source_of_truth**, проверяет их метаданные, 
и **синхронизирует** всё в Postgres так, чтобы дальше работали: фильтры, поиск, граф, агенты и векторизация.

## Что важно не забыть (чек-лист мыслей)

### 1) Что pipeline обязан делать
- Читать контент из source_of_truth (Markdown + frontmatter).
- Парсить документы в структурированные поля (type, status, taxonomy, links).
- Валидировать ссылки на controlled vocabularies (rubric_id/category_id/keyword_id).
- Делать upsert в БД (идемпотентно: повторный запуск не ломает данные).
- Запускать подпроцесс embeddings:
  - **document embeddings** (1 вектор на документ)
  - **chunk embeddings** (векторы на чанки)

### 2) Политики, которые сильно облегчают жизнь (и относятся именно сюда)
- **Политика “что считается изменением” (hash/mtime)**  
  Нужно определить, как pipeline понимает, что документ изменился и требует обновления в БД/векторов.
- **Политика чанкинга** (по заголовкам / по длине / по абзацам)  
  Нужно определить, как резать документ на chunks для chunk-embeddings и RAG.

### 3) Практический смысл этих политик
- Экономия денег и времени: пересчитывать embeddings только когда надо.
- Предсказуемость: одинаковые правила → стабильный индекс и поиск.
- Безопасность: меньше неожиданных “перезаписей” и случайных обновлений.
